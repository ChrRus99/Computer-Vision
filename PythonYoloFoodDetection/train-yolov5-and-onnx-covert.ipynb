{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3739,"status":"ok","timestamp":1689324330451,"user":{"displayName":"Simone Osti","userId":"06515279332524212193"},"user_tz":-120},"id":"Ie5uLDH4uzAp","outputId":"b8b559cc-6b52-45e2-da90-4233ba844195"},"outputs":[],"source":["# clone YOLOv5 repository\n","!git clone https://github.com/ultralytics/yolov5  # clone repo\n","%cd yolov5\n","!git reset --hard 064365d8683fd002e9ad789c1e91fa3d021b44f0"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#install all dependencies\n","!pip install -qr requirements.txt  # install dependencies (ignore errors)\n","import torch\n","\n","!pip install -q roboflow\n","from roboflow import Roboflow"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11081,"status":"ok","timestamp":1689324359633,"user":{"displayName":"Simone Osti","userId":"06515279332524212193"},"user_tz":-120},"id":"wbvMlHd_QwMG","outputId":"4e69d626-0a71-4d92-84e5-ef4c448370db"},"outputs":[],"source":["# install dependencies as necessary\n","#!pip install -qr requirements.txt  # install dependencies (ignore errors)\n","#import torch\n","\n","from IPython.display import Image, clear_output  # to display images\n","from utils.downloads import attempt_download  # to download models/datasets\n","\n","# clear_output()\n","print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28033,"status":"ok","timestamp":1689324401115,"user":{"displayName":"Simone Osti","userId":"06515279332524212193"},"user_tz":-120},"id":"Ug_PhK1oqwQA","outputId":"ac443088-a901-4ac3-f1ca-ec7746479b98"},"outputs":[],"source":["%cd /content/yolov5\n","!pip install roboflow\n","\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\" YOUR PROFILE API\")  #ADD API CONNECTED WITH YOUR PROFILE\n","\n","project = rf.workspace(\"computervision-yanzi\").project(\"cv_group_projects\")\n","dataset = project.version(40).download(\"yolov5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1689324408124,"user":{"displayName":"Simone Osti","userId":"06515279332524212193"},"user_tz":-120},"id":"ZZ3DmmGQztJj","outputId":"edb32a37-91c4-4b96-f59d-712cedb174c6"},"outputs":[],"source":["# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n","%cat {dataset.location}/data.yaml"]},{"cell_type":"markdown","metadata":{"id":"UwJx-2NHsYxT"},"source":["# Define Model Configuration and Architecture\n","\n","We will write a yaml script that defines the parameters for our model like the number of classes, anchors, and each layer.\n","\n","You do not need to edit these cells, but you may."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":470,"status":"ok","timestamp":1689324412520,"user":{"displayName":"Simone Osti","userId":"06515279332524212193"},"user_tz":-120},"id":"dOPn9wjOAwwK","outputId":"c38b9486-c562-466f-fb53-8605374ac9a7"},"outputs":[],"source":["# define number of classes based on YAML\n","import yaml\n","with open(dataset.location + \"/data.yaml\", 'r') as stream:\n","    num_classes = str(yaml.safe_load(stream)['nc'])\n","print(dataset.location)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1689324413010,"user":{"displayName":"Simone Osti","userId":"06515279332524212193"},"user_tz":-120},"id":"1Rvt5wilnDyX","outputId":"464cbb84-9227-409b-b1f7-e337b4eedfbe"},"outputs":[],"source":["#this is the model configuration we will use for our tutorial\n","%cat /content/yolov5/models/yolov5s.yaml"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1689324415828,"user":{"displayName":"Simone Osti","userId":"06515279332524212193"},"user_tz":-120},"id":"t14hhyqdmw6O"},"outputs":[],"source":["#customize iPython writefile so we can write variables\n","from IPython.core.magic import register_line_cell_magic\n","\n","@register_line_cell_magic\n","def writetemplate(line, cell):\n","    with open(line, 'w') as f:\n","        f.write(cell.format(**globals()))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1689324417031,"user":{"displayName":"Simone Osti","userId":"06515279332524212193"},"user_tz":-120},"id":"uDxebz13RdRA"},"outputs":[],"source":["%%writetemplate /content/yolov5/models/custom_yolov5s.yaml\n","\n","# parameters\n","nc: {num_classes}  # number of classes\n","depth_multiple: 0.33  # model depth multiple\n","width_multiple: 0.50  # layer channel multiple\n","\n","# anchors\n","anchors:\n","  - [10,13, 16,30, 33,23]  # P3/8\n","  - [30,61, 62,45, 59,119]  # P4/16\n","  - [116,90, 156,198, 373,326]  # P5/32\n","\n","# YOLOv5 backbone\n","backbone:\n","  # [from, number, module, args]\n","  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n","   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n","   [-1, 3, BottleneckCSP, [128]],\n","   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n","   [-1, 9, BottleneckCSP, [256]],\n","   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n","   [-1, 9, BottleneckCSP, [512]],\n","   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n","   [-1, 1, SPP, [1024, [5, 9, 13]]],\n","   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n","  ]\n","\n","# YOLOv5 head\n","head:\n","  [[-1, 1, Conv, [512, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n","   [-1, 3, BottleneckCSP, [512, False]],  # 13\n","\n","   [-1, 1, Conv, [256, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n","   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n","\n","   [-1, 1, Conv, [256, 3, 2]],\n","   [[-1, 14], 1, Concat, [1]],  # cat head P4\n","   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n","\n","   [-1, 1, Conv, [512, 3, 2]],\n","   [[-1, 10], 1, Concat, [1]],  # cat head P5\n","   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n","\n","   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n","  ]"]},{"cell_type":"markdown","metadata":{"id":"VUOiNLtMP5aG"},"source":["# Train Custom YOLOv5 Detector\n","\n","### Next, we'll fire off training!\n","\n","\n","Here, we are able to pass a number of arguments:\n","- **img:** define input image size\n","- **batch:** determine batch size\n","- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n","- **data:** set the path to our yaml file\n","- **cfg:** specify our model configuration\n","- **weights:** specify a custom path to weights. (Note: you can download weights from the Ultralytics Google Drive [folder](https://drive.google.com/open?id=1Drs_Aiu7xx6S-ix95f9kNsA6ueKRpN2J))\n","- **name:** result names\n","- **nosave:** only save the final checkpoint\n","- **cache:** cache images for faster training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1783220,"status":"ok","timestamp":1689327744197,"user":{"displayName":"Simone Osti","userId":"06515279332524212193"},"user_tz":-120},"id":"1NcFxRcFdJ_O","outputId":"ea557b64-0b25-4cd2-d416-c148028bd052"},"outputs":[],"source":["# train yolov5s on custom data for 400 epochs\n","# time its performance\n","%%time\n","%cd /content/yolov5/\n","!python train.py --img 416 --batch 16 --epochs 400 --data {dataset.location}/data.yaml --cfg ./models/custom_yolov5s.yaml --weights '' --name yolov5s_results  --cache"]},{"cell_type":"markdown","metadata":{"id":"h0Z6pGDENfka"},"source":["# Convert PyTorch Models to ONNX\n","Use this notebook to convert the out of the box PyTorch models to other formats."]},{"cell_type":"markdown","metadata":{"id":"zAM4YNS4M3iC"},"source":["## Clone Ultralytics/yolov5 Repository"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14834,"status":"ok","timestamp":1689330674856,"user":{"displayName":"Simone Osti","userId":"06515279332524212193"},"user_tz":-120},"id":"IZ34ujwgFs45","outputId":"6c4064a1-4d96-4989-abd6-bfa842626382"},"outputs":[],"source":["!git clone https://github.com/ultralytics/yolov5\n","%cd yolov5\n","!pip install -r requirements.txt\n","!pip install onnx"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5603,"status":"ok","timestamp":1689330680455,"user":{"displayName":"Simone Osti","userId":"06515279332524212193"},"user_tz":-120},"id":"ik9DeHkEwcOJ","outputId":"c7cc1622-f5a5-4a41-f5e6-18b47f3eddb9"},"outputs":[],"source":["!pip install torch torchvision"]},{"cell_type":"markdown","metadata":{"id":"zeAU7NDTNEZa"},"source":["## Export to ONNX"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7012,"status":"ok","timestamp":1689330692549,"user":{"displayName":"Simone Osti","userId":"06515279332524212193"},"user_tz":-120},"id":"pmdArH0IzvaX","outputId":"9e4de869-9fc5-44e5-e8f4-2ad3915d1970"},"outputs":[],"source":["!pip install --upgrade onnx"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13370,"status":"ok","timestamp":1689330733038,"user":{"displayName":"Simone Osti","userId":"06515279332524212193"},"user_tz":-120},"id":"V1DQQY3hwcOL","outputId":"aa57f554-2f8f-406f-93a7-2fda9409a02c"},"outputs":[],"source":["# The default input size is 640x640.\n","!python export.py --weights /content/yolov5/runs/train/yolov5s_results/weights/best.pt --include onnx --imgsz 640 640 --opset 11\n"]},{"cell_type":"markdown","metadata":{"id":"CO79jn9CNIw4"},"source":["## Download the ONNX Models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ITUKhgc2P4T6"},"outputs":[],"source":["# For colab environment.\n","from google.colab import files\n","files.download('/content/yolov5/runs/train/yolov5s_results/weights/best.onnx')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/roboflow-ai/notebooks/blob/main/notebooks/train-yolov5-object-detection-on-custom-data.ipynb","timestamp":1686324133451}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
